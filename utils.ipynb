{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting speaker and utt ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/1546: 12-12-2023-24\n",
      "Processing file 2/1546: redelivery-11-07-2023-11\n",
      "Processing file 3/1546: 23-02-2024-05\n",
      "Processing file 4/1546: redelivery-11-01-2024-02-03\n",
      "Processing file 5/1546: 11-01-2024-15\n",
      "Processing file 6/1546: 12-12-2023-58\n",
      "Processing file 7/1546: redelivery-05-01-2024-42-03\n",
      "Processing file 8/1546: redelivery-06-08-2023-09-03\n",
      "Processing file 9/1546: 31-03-2024-02\n",
      "Processing file 10/1546: redelivery-06-07-2023-06-02\n",
      "Processing file 11/1546: 20-12-2023-46\n",
      "Processing file 12/1546: redelivery-02-08-2023-02-03\n",
      "Processing file 13/1546: 08-07-2023-04\n",
      "Processing file 14/1546: 31-03-2024-27\n",
      "Processing file 15/1546: 25-05-2024-02\n",
      "Processing file 16/1546: redelivery-05-01-2024-43-03\n",
      "Processing file 17/1546: 18-10-2023-33\n",
      "Processing file 18/1546: redelivery-10-07-2023-13\n",
      "Processing file 19/1546: 12-12-2023-61\n",
      "Processing file 20/1546: 18-10-2023-47\n",
      "Processing file 21/1546: redelivery-05-01-2024-52-03\n",
      "Processing file 22/1546: 19-01-2024-17\n",
      "Processing file 23/1546: 12-12-2023-31\n",
      "Processing file 24/1546: redelivery-18-10-2023-50-03\n",
      "Processing file 25/1546: redelivery-06-07-2023-11-02\n",
      "Processing file 26/1546: 30-11-2023-39\n",
      "Processing file 27/1546: 11-01-2024-22\n",
      "Processing file 28/1546: 28-01-2024-33\n",
      "Processing file 29/1546: redelivery-26-09-2023-40-03\n",
      "Processing file 30/1546: redelivery-09-07-2023-12\n",
      "Processing file 31/1546: 19-01-2024-34\n",
      "Processing file 32/1546: 05-03-2024-24\n",
      "Processing file 33/1546: 07-02-2024-17\n",
      "Processing file 34/1546: 12-12-2023-64\n",
      "Processing file 35/1546: 31-08-2023-27\n",
      "Processing file 36/1546: redelivery-02-08-2023-47-03\n",
      "Processing file 37/1546: 23-02-2024-41\n",
      "Processing file 38/1546: redelivery-06-08-2023-02-03\n",
      "Processing file 39/1546: 12-04-2024-15\n",
      "Processing file 40/1546: 07-02-2024-03\n",
      "Processing file 41/1546: redelivery-18-10-2023-62-03\n",
      "Processing file 42/1546: 11-01-2024-55\n",
      "Processing file 43/1546: 26-09-2023-29\n",
      "Processing file 44/1546: redelivery-20-12-2023-25-03\n",
      "Processing file 45/1546: redelivery-31-08-2023-21-03\n",
      "Processing file 46/1546: 23-02-2024-09\n",
      "Processing file 47/1546: redelivery-12-12-2023-14-03\n",
      "Processing file 48/1546: 26-09-2023-04\n",
      "Processing file 49/1546: 11-01-2024-03\n",
      "Processing file 50/1546: redelivery-06-07-2023-10-02\n",
      "Processing file 51/1546: 07-02-2024-31\n",
      "Processing file 52/1546: redelivery-11-07-2023-01-02\n",
      "Processing file 53/1546: 11-07-2023-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/Root_content/Vaani/Response_to_questions/MegaPrecheckList/phase1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Call the function with a limit of 5 files for testing\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mextract_ids_from_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36mextract_ids_from_files\u001b[0;34m(folder_path, max_files)\u001b[0m\n\u001b[1;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Process each row in the chunk\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     30\u001b[0m         first_column \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_column, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m first_column\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/pandas/core/frame.py:1400\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1398\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1400\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1402\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/pandas/core/series.py:509\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    507\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/pandas/core/construction.py:569\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    567\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 569\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subarr \u001b[38;5;129;01mis\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m copy:\n\u001b[1;32m    572\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m subarr\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:1204\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[0;32m-> 1204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[1;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_datetime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM8[ns]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2445\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/numpy/core/numeric.py:345\u001b[0m, in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    343\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    344\u001b[0m a \u001b[38;5;241m=\u001b[39m empty(shape, dtype, order)\n\u001b[0;32m--> 345\u001b[0m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcopyto\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extract_ids_from_files(folder_path, max_files=None):\n",
    "    speaker_utt_pairs = set()\n",
    "    \n",
    "    # Walk through the folder and its subfolders\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    # Limit the number of files to process\n",
    "    if max_files:\n",
    "        file_paths = file_paths[:max_files]\n",
    "    \n",
    "    for idx, file_path in enumerate(file_paths):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Processing file {idx + 1}/{len(file_paths)}: {file_name}\")\n",
    "        \n",
    "        # Try reading the file as a TSV\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep='\\t', chunksize=1000)\n",
    "            \n",
    "            for chunk in df:\n",
    "                # Process each row in the chunk\n",
    "                for _, row in chunk.iterrows():\n",
    "                    first_column = row[0]\n",
    "                    if isinstance(first_column, str) and first_column.startswith('/'):\n",
    "                        basename = os.path.basename(first_column)\n",
    "                        parts = basename.split(\"_\")\n",
    "                        if len(parts) >= 4:\n",
    "                            speakerid = parts[2]\n",
    "                            uttid = parts[3]\n",
    "                            speaker_utt_pairs.add((speakerid, uttid))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {file_name}: {e}\")\n",
    "    \n",
    "    # Create a DataFrame from the unique speaker-utt pairs\n",
    "    result_df = pd.DataFrame(list(speaker_utt_pairs), columns=['SpeakerID', 'UttID'])\n",
    "    \n",
    "    # Save the DataFrame to a new TSV file\n",
    "    result_df.to_csv('unique_speaker_utt_ids.tsv', sep='\\t', index=False)\n",
    "    print(\"Completed. The unique speaker and utterance IDs have been saved to 'unique_speaker_utt_ids.tsv'.\")\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = r'/data/Root_content/Vaani/Response_to_questions/MegaPrecheckList/phase1'\n",
    "\n",
    "# Call the function with a limit of 5 files for testing\n",
    "extract_ids_from_files(folder_path, max_files=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
